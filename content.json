{"pages":[{"title":"about","text":"About개인 블로그 통계 1import 개발언어 as 기계학습 등등","link":"/about/index.html"}],"posts":[{"title":"Scikit-learn Basic","text":"# Workflow Load data Data transformation Pipeline을 이용한 모델 학습 및 예측 Load data데이터 다운 및 읽기 1from sklearn.datasets import fetch_20newsgroups 123cats = ['alt.atheism', 'sci.space']newsgroups_train = fetch_20newsgroups(subset='train', categories=cats)newsgroups_test = fetch_20newsgroups(subset='test', categories=cats) 1234X_train = newsgroups_train.dataX_test = newsgroups_test.datay_train = newsgroups_train.targety_test = newsgroups_test.target 1234len(X_train),\\len(X_test),\\y_train.shape,\\y_test.shape (1073, 713, (1073,), (713,)) 12print(X_train[0])print(&quot;[Label: {}]&quot;.format(y_train[0])) From: bil@okcforum.osrhe.edu (Bill Conner) Subject: Re: Not the Omni! Nntp-Posting-Host: okcforum.osrhe.edu Organization: Okcforum Unix Users Group X-Newsreader: TIN [version 1.1 PL6] Lines: 18 Charley Wingate (mangoe@cs.umd.edu) wrote: : : &gt;&gt; Please enlighten me. How is omnipotence contradictory? : : &gt;By definition, all that can occur in the universe is governed by the rules : &gt;of nature. Thus god cannot break them. Anything that god does must be allowed : &gt;in the rules somewhere. Therefore, omnipotence CANNOT exist! It contradicts : &gt;the rules of nature. : : Obviously, an omnipotent god can change the rules. When you say, &quot;By definition&quot;, what exactly is being defined; certainly not omnipotence. You seem to be saying that the &quot;rules of nature&quot; are pre-existant somehow, that they not only define nature but actually cause it. If that's what you mean I'd like to hear your further thoughts on the question. Bill [Label: 0] Data Transformation1from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer 12vect = CountVectorizer()tfidf = TfidfTransformer() Pipeline을 이용한 학습 구성필요한 모델 Estimator 인스턴트화123from sklearn.metrics import f1_scorefrom sklearn.model_selection import cross_val_scorefrom sklearn.svm import LinearSVC 1clf = LinearSVC() PipelinePipeline은 모델의 학습 과정에 포함되는 몇가지의 단계를 단순화해주는 기능이다. 이를 통해, 최종 모델을 위한 재학습이나 Cross-validation 등을 위해 학습을 반복하는 상황에서, Pipeline을 이용하면 이를 쉽고 간편하게 진행할 수 있다. 1from sklearn.pipeline import Pipeline 12345pipeline = Pipeline([ ('vect',vect), ('tfidf',tfidf), ('clf',clf)]) Test set 검증123456# now train and predict test instancespipeline.fit(X_train,y_train)y_preds = pipeline.predict(X_test)# calculate f1f1_score(y_test, y_preds, average='micro') 0.9747545582047685 Cross validationCV를 위해서는 데이터의 변환, 학습, 평가를 k번 만큼 진행해야 한다. 따라서 위에서 만든 pipeline을 이용하여 CV를 사용한다 1import numpy as np 12X = np.append(X_train, X_test)y = np.append(y_train, y_test) 123scores = cross_val_score(pipeline,X,y,cv=5,scoring='f1_micro')scores array([0.99162011, 0.99159664, 1. , 0.9859944 , 0.99439776]) 1scores.mean() 0.9927217814500102 Grid search모델 최적화를 위한 파라미터 탐색에 사용되는 Grid Search 방법을 적용하기 위해서도 반복적인 학습이 필요하다. Grid Search를 통한 파라미터 최적화도 pipeline을 통해 쉽게 구성할 수 있다 파라미터 최적화를 위해서, 각 파이프라인을 구성하는 함수들에서 최적화 하고싶은 파라미터들의 범위를 설정한다| 123456789101112param_grid = [ { 'vect__max_df':[0.8,0.9,1.0], 'clf__penalty':['l2'], 'clf__dual':[True,False] }, { 'vect__max_df':[0.8,0.9,1.0], 'clf__penalty':['l1'], 'clf__dual': [False] }] GridSearchCV는 Cross validation 에서 각 k마다 Grid Search를 통해 파라미터를 최적화하는 방법이다 1from sklearn.model_selection import GridSearchCV 12grid = GridSearchCV(pipeline, cv=5, param_grid=param_grid, scoring='f1_micro')grid.fit(X_train,y_train) GridSearchCV(cv=5, error_score=nan, estimator=Pipeline(memory=None, steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict', dtype=&lt;class 'numpy.int64'&gt;, encoding='utf-8', input='content', lowercase=True, max_df=1.0, max_features=None, min_df=1, ngram_range=(1, 1), preprocessor=None, stop_words=None, strip_accents=None, token_pattern='(?u)... penalty='l2', random_state=None, tol=0.0001, verbose=0))], verbose=False), iid='deprecated', n_jobs=None, param_grid=[{'clf__dual': [True, False], 'clf__penalty': ['l2'], 'vect__max_df': [0.8, 0.9, 1.0]}, {'clf__dual': [False], 'clf__penalty': ['l1'], 'vect__max_df': [0.8, 0.9, 1.0]}], pre_dispatch='2*n_jobs', refit=True, return_train_score=False, scoring='f1_micro', verbose=0) 최적 파라미터 1print(&quot;Best: %f using %s&quot; % (grid.best_score_, grid.best_params_)) Best: 0.994414 using {'clf__dual': True, 'clf__penalty': 'l2', 'vect__max_df': 0.8} 전체 실험결과 12345means = grid.cv_results_['mean_test_score']stds = grid.cv_results_['std_test_score']params = grid.cv_results_['params']for mean, stdev, param in zip(means, stds, params): print(&quot;%f (%f) with: %r&quot; % (mean, stdev, param)) 0.994414 (0.003479) with: {'clf__dual': True, 'clf__penalty': 'l2', 'vect__max_df': 0.8} 0.994414 (0.003479) with: {'clf__dual': True, 'clf__penalty': 'l2', 'vect__max_df': 0.9} 0.993484 (0.004742) with: {'clf__dual': True, 'clf__penalty': 'l2', 'vect__max_df': 1.0} 0.994414 (0.003479) with: {'clf__dual': False, 'clf__penalty': 'l2', 'vect__max_df': 0.8} 0.994414 (0.003479) with: {'clf__dual': False, 'clf__penalty': 'l2', 'vect__max_df': 0.9} 0.993484 (0.004742) with: {'clf__dual': False, 'clf__penalty': 'l2', 'vect__max_df': 1.0} 0.972984 (0.009003) with: {'clf__dual': False, 'clf__penalty': 'l1', 'vect__max_df': 0.8} 0.972984 (0.011150) with: {'clf__dual': False, 'clf__penalty': 'l1', 'vect__max_df': 0.9} 0.974853 (0.011596) with: {'clf__dual': False, 'clf__penalty': 'l1', 'vect__max_df': 1.0} 최적 파라미터를 통한 Test accuracy. 파라미터를 최적화하지 않았을 때보다 근소하게 accuracy가 증가했다. 12345678# now train and predict test instances# using the best configspipeline.set_params(clf__penalty='l2',vect__max_df=0.9,clf__dual=True)pipeline.fit(X_train,y_train)y_preds = pipeline.predict(X_test)# calculate f1f1_score(y_test, y_preds, average='micro') 0.9761570827489481 1","link":"/2020/10/07/Basic/"},{"title":"Make your own Blog with Hexo on Windows","text":"# 환경 설정Hexo를 이용하여 blog를 만들기 위해서는 Node.js와 Git 두가지가 필요하다. 아래 링크를 통해 각 사이트에서 권장하는 version을 다운받고, default option 으로 설치한다 Node.js Git Hexo 설치Node.js 설치 후 Window 검색창에서 Node.js command prompt를 검색 및 실행 후 다음의 명령어를 입력하여 Hexo를 설치한다. 1npm install -g hexo-cli Hexo 설치 후 원하는 Local directory에 다음 명령어를 실행한다. 1hexo init &lt;폴더명&gt; hexo 기본 폴더는 Local directory 하위에 생성이 된다.hexo 기본 폴더에는 기본적인 페이지 및 기능을 포함하고 있는 파일들이 있다. hexo 기본 폴더에서 다음과 같은 명령어를 실행하여 로컬 서버를 실행한다. 1hexo server 브라우저에서 http://0.0.0.0:4000/ 혹은 http://localhost:4000/ 로 접속하면 블로그를 확인할 수 있다. 새 Post 만들기","link":"/2020/10/07/hexo/hexo_icarus_tutorial/"}],"tags":[{"name":"ML","slug":"ML","link":"/tags/ML/"},{"name":"scikit-learn","slug":"scikit-learn","link":"/tags/scikit-learn/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"icarus","slug":"icarus","link":"/tags/icarus/"}],"categories":[{"name":"ML","slug":"ML","link":"/categories/ML/"},{"name":"Hexo","slug":"Hexo","link":"/categories/Hexo/"}]}